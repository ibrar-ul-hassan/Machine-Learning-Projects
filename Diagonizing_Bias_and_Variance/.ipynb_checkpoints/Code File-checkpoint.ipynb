{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b762718",
   "metadata": {},
   "source": [
    "# Diagnosing Bias and Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9442c8",
   "metadata": {},
   "source": [
    "Once we understand the learning algorithm's performance by measuring its training and cross validation error. Given on these values, we are able to quantify how well a model is doing and this helps us make a decision on which one to use for a given application.\n",
    "\n",
    "**In this project**, we will build upon this process and explore some tips to improve the perfomance of our models. As it turns out, the training and cross validation errors can tell you what to try next to improve our models. \n",
    "\n",
    "Specifically, it will show if we have a bias bias (underfitting) or high variance (overfitting) problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f50c65b",
   "metadata": {},
   "source": [
    "<img src=\"Bias and Variance explanation.png\" width=75%>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7528d9d8",
   "metadata": {},
   "source": [
    "**Problem:**\n",
    "\n",
    "The *leftmost figure* shows a high bias problem where the model is not capturing the patters in the training data. As a result, we will have a high training and cross validation error.\n",
    "\n",
    "The *rightmost figure,* on the other hand, shows a high variance problem where the model had overfit the training set. Thus, even though it has a low training error, it will perform poorly on new examples. This is indicated by high cross validation error.\n",
    "\n",
    "The ideal model would be the *figure in the middle*, where it successfully learn from the training set and also generalizes well to unseen data. \n",
    "\n",
    "To **fix a high bias problem**, we can:\n",
    "\n",
    "* try adding polynomial features\n",
    "* try getting additional features\n",
    "* try decreasing the regularization parameter\n",
    "\n",
    "To **fix a high variance problem**, we can:\n",
    "\n",
    "* try smaller set of features\n",
    "* try getting more training examples\n",
    "* try increasing the regularization parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bca4ae6",
   "metadata": {},
   "source": [
    "# Establishing the Baseline of Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6442da60",
   "metadata": {},
   "source": [
    "Before you can diagose a model for high bias or high variance, it is usually helful to first have an idea of what level of error you can reasonably get to.\n",
    "\n",
    "We can use any of the following to set a baseline level of performance.\n",
    "* Human level performance\n",
    "* competing algorithm's performance\n",
    "* guess based on experience\n",
    "\n",
    "**Real-world data** can be very noisy and it's often infeasible to get to 0% error. For example, you might think that you have a high bias problem because you're getting 10% training and 15% cross validation error on a computer vision application. However, you later found out that even humans can't perform better than 10% error. If you consider this the baseline level, then you now instead have a high variance problem because you've prioritized minimizing the gap between cross validation and training error.\n",
    "\n",
    "With this in mind, let's begin exploring the techniques to address these issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e224b22e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
